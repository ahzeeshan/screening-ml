{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import scipy.io as spio\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor, kernels\n",
    "import shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lattice = 'cubic'\n",
    "coeff=0\n",
    "data = spio.loadmat(lattice+'-data-posd-with-den.mat')\n",
    "X = data['xdata']\n",
    "y = data['ydata'][:,coeff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.4804800e+02  1.4727705e+01  0.0000000e+00  6.3059300e-01\n",
      "  1.0400000e+00  1.8000000e+01  6.0000000e+00  3.1312620e+00\n",
      "  2.8888900e-01  1.8000000e+01  8.0000000e+00  2.7513770e+00\n",
      "  1.9636940e+01  2.7513770e+00  1.6975000e-02  1.6691922e+01\n",
      "  3.6000000e+00  1.0000000e+00 -4.1742500e-01  1.6692338e+01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mp-861931'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[2,:])\n",
    "data['mps'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.delete(X,18,axis=1)\n",
    "X1.shape\n",
    "X1[2,:]\n",
    "X=X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_parameters = {\n",
    "  'lasso': (linear_model.Lasso(),\n",
    "              {'reg__alpha': [0.01, 0.1, 0.5, 1.,5.,10.]}),\n",
    "    'elnet': (linear_model.ElasticNet(),\n",
    "              {'reg__alpha':[0.01, 0.1, 0.5, 1, 5., 10.], 'reg__l1_ratio':[0.,0.1,0.5,1.,2.1]}),\n",
    "    'krg': (KernelRidge(),\n",
    "            {'reg__kernel':['rbf','linear'], 'reg__alpha': [1e0, 0.1, 1e-2, 1e-3], 'reg__gamma': np.logspace(-2, 2, 5)}),\n",
    "    'gpr': (GaussianProcessRegressor(kernel = kernels.RBF()),\n",
    "            {'reg__kernel__length_scale':[0.01, 0.1, 1., 2., 10., 100.], 'reg__kernel__length_scale_bounds':[(1e-2,1.),(1e-1,1.),(1e-1,10.),(1.,10.),(1.,100.)\\\n",
    ",(1e-2,1e2)]}),\n",
    "    'gbr': (GradientBoostingRegressor(learning_rate=0.01, min_samples_split=2, max_features='sqrt', loss='ls', subsample=0.4),\n",
    "            {'reg__max_depth': [2,3,4,10,20,50],'reg__min_samples_leaf': [2,3,4,10], 'reg__learning_rate':[0.01, 0.1], 'reg__max_features':['auto', 'sqrt', 'l\\\n",
    "og2']}),\n",
    "    'ada': (AdaBoostRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=500,learning_rate=0.01),#max_depth alone doesn't work probably               \n",
    "            {'reg__base_estimator__max_depth': [2,3,4,10], 'reg__base_estimator':[DecisionTreeRegressor(max_depth = 4, max_features='auto'),\n",
    "                                                                                    DecisionTreeRegressor(max_depth = None, max_features='auto'),\n",
    "                                                                                    DecisionTreeRegressor(max_depth = 4, max_features='sqrt'),\n",
    "                                                                                     DecisionTreeRegressor(max_depth = None, max_features='sqrt')]}),\n",
    "    'svr': (SVR(),\n",
    "            {'reg__C': [0.01, 0.05, 0.1, 1], 'reg__kernel': ['linear', 'rbf']}),\n",
    "    'rf': (RandomForestRegressor(),\n",
    "           {'reg__max_depth': [None, 5, 10, 50]}),\n",
    "    'brg': (linear_model.BayesianRidge(fit_intercept=True),\n",
    "            {'reg__alpha_1': [1.e-6, 1.e-5]}),\n",
    "    'lars': (linear_model.Lars(fit_intercept = True, normalize=False),\n",
    "             {'reg__n_nonzero_coefs': [5, 10, 50, 500, np.inf]}),\n",
    "    'ard': (linear_model.ARDRegression(),\n",
    "            {'reg__alpha_1':[1.e-6, 1.e-5]})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "inner_cv = KFold(n_splits=3, shuffle=True)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(),n_estimators=500,learning_rate=0.01)\n",
    "params = {'reg__max_depth': [None,2,5,100],'reg__max_features':['auto','sqrt','log2'],'reg__min_samples_split':[2,3,4],'reg__min_samples_leaf':[2,3,4]}\n",
    "params = {'reg__base_estimator__max_depth': [None,2,4,10,100],\n",
    "            'reg__base_estimator__max_features':['auto','sqrt','log2',None],\n",
    "            'reg__base_estimator__min_samples_split':[2,3,4],\n",
    "            'reg__base_estimator__min_samples_leaf': [1,2,3,4]}\n",
    "#params = {'reg__base_estimator':[DecisionTreeRegressor(max_depth = 4, max_features='auto'),\n",
    "#                                DecisionTreeRegressor(max_depth = None, max_features='auto'),\n",
    "#                                DecisionTreeRegressor(max_depth = 4, max_features='sqrt'),\n",
    "#                                DecisionTreeRegressor(max_depth = None, max_features='sqrt')]}\n",
    "pipeline = Pipeline([('transformer', scaler), ('reg', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1 = GridSearchCV(estimator=pipeline, param_grid=params, cv=inner_cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not to run\n",
    "model=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=100,\n",
    "                                                            max_features='log2',\n",
    "                                                            min_samples_leaf= 3,\n",
    "                                                            min_samples_split= 3))\n",
    "pipeline = Pipeline([('transformer', scaler), ('reg', model)])\n",
    "reg1 = Pipeline([('transformer', scaler), ('reg', model)])\n",
    "#clf.fit(X,y)\n",
    "#clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg__base_estimator__max_depth': 100, 'reg__base_estimator__max_features': 'log2', 'reg__base_estimator__min_samples_leaf': 3, 'reg__base_estimator__min_samples_split': 3}\n",
      "[0.77268395 0.39346309 0.54305701]\n",
      "Cross-validation results:\n",
      "Folds: 3, mean r2: 0.570\n",
      "101.58333333333334\n"
     ]
    }
   ],
   "source": [
    "#One with GridSearch\n",
    "reg1.fit(X,y)\n",
    "print(reg1.best_params_)\n",
    "#scores=cross_val_score(reg1, X=X, y=y, scoring='neg_mean_squared_error',cv=outer_cv)\n",
    "r2scores=cross_val_score(reg1, X=X, y=y, scoring='r2',cv=outer_cv)\n",
    "#rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "#print(rmse_scores)\n",
    "print(r2scores)\n",
    "print('Cross-validation results:')\n",
    "#print('Folds: %i, mean RMSE: %.3f' % (len(scores), np.mean(np.abs(rmse_scores))))\n",
    "print('Folds: %i, mean r2: %.3f' % (len(r2scores), np.mean(r2scores)))\n",
    "print(sum(y-reg1.predict(X)))\n",
    "#print(y-reg1.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79404276 0.55647594 0.7017167 ]\n",
      "Cross-validation results:\n",
      "Folds: 3, mean r2: 0.684\n"
     ]
    }
   ],
   "source": [
    "reg1.fit(X,y)\n",
    "#print(reg1.best_params_)\n",
    "#scores=cross_val_score(reg1, X=X, y=y, scoring='neg_mean_squared_error',cv=outer_cv)\n",
    "r2scores=cross_val_score(reg1, X=X, y=y, scoring='r2',cv=outer_cv)\n",
    "#rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "#print(rmse_scores)\n",
    "print(r2scores)\n",
    "print('Cross-validation results:')\n",
    "#print('Folds: %i, mean RMSE: %.3f' % (len(scores), np.mean(np.abs(rmse_scores))))\n",
    "print('Folds: %i, mean r2: %.3f' % (len(r2scores), np.mean(r2scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reg__base_estimator__max_depth': 100, 'reg__base_estimator__max_features': 'log2', 'reg__base_estimator__min_samples_leaf': 3, 'reg__base_estimator__min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "print(reg1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntdata = spio.loadmat(lattice+'-non-training-data-with-den.mat')\n",
    "Xnt = ntdata['xntdata']\n",
    "Xnt=np.delete(Xnt,18,axis=1)\n",
    "ynt1=reg1.predict(Xnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.figrecipes.plotly.make_plots import PlotlyFig\n",
    "\n",
    "pf_rf = PlotlyFig(x_title='DFT (MP) C11 (GPa)',\n",
    "                  y_title='Random Forest C11 (GPa)',\n",
    "                  plot_title='Random forest regression',\n",
    "                  plot_mode='offline',\n",
    "                  margin_left=150,\n",
    "                  textsize=35,\n",
    "                  ticksize=30,\n",
    "                  filename=\"rf_regression1.html\")\n",
    "\n",
    "# a line to represent a perfect model with 1:1 prediction\n",
    "xy_line = {'x_col': [0, max(y)],\n",
    "           'y_col': [0, max(y)],\n",
    "           'color': 'black',\n",
    "           'mode': 'lines',\n",
    "           'legend': None,\n",
    "           'text': None,\n",
    "           'size': None}\n",
    "\n",
    "pf_rf.xy_plot(x_col=y,\n",
    "              y_col=reg1.predict(X),\n",
    "              size=3,\n",
    "              marker_outline_width=0.5,\n",
    "              #text=df_mp['pretty_formula'],\n",
    "              add_xy_plot=[xy_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dump(reg1,open( \"reg1_noform.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff=1\n",
    "y = data['ydata'][:,coeff]\n",
    "params=models_and_parameters['lasso'][1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "inner_cv = KFold(n_splits=3, shuffle=True)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('transformer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reg', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'reg__alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=linear_model.Lasso()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pipeline = Pipeline([('transformer', scaler), ('reg', model)])\n",
    "reg2 = GridSearchCV(estimator=pipeline, param_grid=params, cv=inner_cv,n_jobs=-1)\n",
    "reg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Folds: 3, mean RMSE: 16.915\n",
      "Folds: 3, mean r2: 0.846\n"
     ]
    }
   ],
   "source": [
    "reg2.fit(X,y)\n",
    "reg2.best_params_\n",
    "scores=cross_val_score(reg2, X=X, y=y, scoring='neg_mean_squared_error',cv=outer_cv)\n",
    "r2scores=cross_val_score(reg2, X=X, y=y, scoring='r2',cv=outer_cv)\n",
    "rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "print('Cross-validation results:')\n",
    "print('Folds: %i, mean RMSE: %.3f' % (len(scores), np.mean(np.abs(rmse_scores))))\n",
    "print('Folds: %i, mean r2: %.3f' % (len(r2scores), np.mean(r2scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.figrecipes.plotly.make_plots import PlotlyFig\n",
    "pf_rf = PlotlyFig(x_title='DFT (MP) C12 (GPa)',\n",
    "                  y_title='Bayesian Ridge C12 (GPa)',\n",
    "                  plot_title='Random forest regression',\n",
    "                  plot_mode='offline',\n",
    "                  margin_left=150,\n",
    "                  textsize=35,\n",
    "                  ticksize=30,\n",
    "                  filename=\"br2_regression1.html\")\n",
    "\n",
    "# a line to represent a perfect model with 1:1 prediction\n",
    "xy_line = {'x_col': [min(y), max(y)],\n",
    "           'y_col': [min(y), max(y)],\n",
    "           'color': 'black',\n",
    "           'mode': 'lines',\n",
    "           'legend': None,\n",
    "           'text': None,\n",
    "           'size': None}\n",
    "\n",
    "\n",
    "pf_rf.xy_plot(x_col=y,\n",
    "              y_col=reg2.predict(X),\n",
    "              size=3,\n",
    "              marker_outline_width=0.5,\n",
    "              #text=df_mp['pretty_formula'],\n",
    "              add_xy_plot=[xy_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dump(reg2,open( \"reg2_noform.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff=2\n",
    "y = data['ydata'][:,coeff]\n",
    "params=models_and_parameters['brg'][1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "inner_cv = KFold(n_splits=3, shuffle=True)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True)\n",
    "model=linear_model.BayesianRidge(normalize=False)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pipeline = Pipeline([('transformer', scaler), ('reg', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72590485 0.78405826 0.6265607 ]\n",
      "Cross-validation results:\n",
      "Folds: 3, mean r2: 0.712\n"
     ]
    }
   ],
   "source": [
    "reg3 = GridSearchCV(estimator=pipeline, param_grid=params, cv=inner_cv,n_jobs=-1)\n",
    "reg3\n",
    "reg3.fit(X,y)\n",
    "reg3.best_params_\n",
    "scores=cross_val_score(reg3, X=X, y=y, scoring='neg_mean_squared_error',cv=outer_cv)\n",
    "r2scores=cross_val_score(reg3, X=X, y=y, scoring='r2',cv=outer_cv)\n",
    "print(r2scores)\n",
    "rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "print('Cross-validation results:')\n",
    "#print('Folds: %i, mean RMSE: %.3f' % (len(scores), np.mean(np.abs(rmse_scores))))\n",
    "print('Folds: %i, mean r2: %.3f' % (len(r2scores), np.mean(r2scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matminer.figrecipes.plotly.make_plots import PlotlyFig\n",
    "pf_rf = PlotlyFig(x_title='DFT (MP) C44 (GPa)',\n",
    "                  y_title='Bayesian Ridge C44 (GPa)',\n",
    "                  plot_title='Random forest regression',\n",
    "                  plot_mode='offline',\n",
    "                  margin_left=150,\n",
    "                  textsize=35,\n",
    "                  ticksize=30,\n",
    "                  filename=\"br3_regression1.html\")\n",
    "\n",
    "# a line to represent a perfect model with 1:1 prediction\n",
    "xy_line = {'x_col': [min(y), max(y)],\n",
    "           'y_col': [min(y), max(y)],\n",
    "           'color': 'black',\n",
    "           'mode': 'lines',\n",
    "           'legend': None,\n",
    "           'text': None,\n",
    "           'size': None}\n",
    "\n",
    "pf_rf.xy_plot(x_col=y,\n",
    "              y_col=reg3.predict(X),\n",
    "              size=3,\n",
    "              marker_outline_width=0.5,\n",
    "              #text=df_mp['pretty_formula'],\n",
    "              add_xy_plot=[xy_line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dump(reg3,open( \"reg3_noform.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.41702297585702\n",
      "197.05481972699144\n",
      "158.26740359133254\n",
      "112.14214679707378\n",
      "232.65033305792758\n",
      "158.26740359133254\n",
      "\n",
      "0.98006455634168\n",
      "0.854755349177047\n",
      "0.6882464206315353\n",
      "0.9405688510174358\n",
      "0.9200212242959691\n",
      "0.6882464206315353\n"
     ]
    }
   ],
   "source": [
    "y1t=reg1.predict(X)\n",
    "y2t=reg2.predict(X)\n",
    "y3t=reg3.predict(X)\n",
    "e1t=(y1t+2*y2t)/3\n",
    "e2t=(y1t-y2t)\n",
    "e3t=y3t\n",
    "from sklearn.metrics import *\n",
    "yall = data['ydata']\n",
    "print(mean_squared_error(y1t,yall[:,0]))\n",
    "print(mean_squared_error(y2t,yall[:,1]))\n",
    "print(mean_squared_error(y3t,yall[:,2]))\n",
    "print(mean_squared_error(e1t,(yall[:,0]+2.*yall[:,1])/3.))\n",
    "print(mean_squared_error(e2t,yall[:,0]-yall[:,1]))\n",
    "print(mean_squared_error(e3t,yall[:,2]))\n",
    "print()\n",
    "print(r2_score(y1t,yall[:,0]))\n",
    "print(r2_score(y2t,yall[:,1]))\n",
    "print(r2_score(y3t,yall[:,2]))\n",
    "print(r2_score(e1t,(yall[:,0]+2.*yall[:,1])/3.))\n",
    "print(r2_score(e2t,yall[:,0]-yall[:,1]))\n",
    "print(r2_score(e3t,yall[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1nt=reg1.predict(Xnt)\n",
    "y2nt=reg2.predict(Xnt)\n",
    "y3nt=reg3.predict(Xnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynt=np.column_stack((y1nt,y2nt,y3nt))\n",
    "ynt.shape\n",
    "spio.savemat(lattice+'-nt-result',mdict={'coeffsnt':ynt,'coord':ntdata['coord'],'mps':ntdata['mps'],'volrat':ntdata['volrat']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2581988  0.38035522 0.38049773 0.25820269 0.38049772 0.08406202\n",
      " 0.38049773 0.25820563 0.25820563 0.2581988  0.2581988  0.08406202\n",
      " 0.25820563 0.08406202 0.25820563 0.25820563 0.25820563 0.25820563\n",
      " 0.73524312 0.23805073 0.23356835 0.23244811 0.38049773 0.08406202\n",
      " 0.25820563 0.08406202 0.15191745 0.15191745 0.05525574 0.25819966\n",
      " 0.25820364 0.25820563 0.25819916 0.25819966 0.25820563 0.25819966\n",
      " 0.25820121 0.25820563 0.25820392 0.25819651 0.25820563 0.14101352\n",
      " 0.25820563 0.25820478 0.25820563 0.25820563 0.15191745 0.25820029\n",
      " 0.25820336 0.2581988  0.25820563 0.25820563 0.15191745 0.2581988\n",
      " 0.15191744 0.1579381  0.16420279 0.25820563 0.25820563 0.25820563\n",
      " 0.2581988  0.25820364 0.25820051 0.25820563 0.25820563 0.25819966\n",
      " 0.25820336 0.25819368 0.25820165 0.25820563 0.25820321 0.25820392\n",
      " 0.25820165 0.0538958  0.25819872 0.25820563 0.25820563 0.25820563\n",
      " 0.25820279 0.25819966 0.15191745 0.2581988  0.25820563 0.25819966\n",
      " 0.25820336 0.25819966 0.25820078 0.14623936 0.15191735 0.25820563\n",
      " 0.25820563 0.25820563 0.2581988  0.25820563 0.2581988  0.2581988\n",
      " 0.25820563 0.2581988  0.2581988  0.25820222 0.25820256 0.15317525\n",
      " 0.25820364 0.25820051 0.25820563 0.25820563 0.25820563 0.25819966\n",
      " 0.25820563 0.25820392 0.25820478 0.2581988  0.15191744 0.25820563\n",
      " 0.25820275 0.25820563 0.15191745 0.25820332 0.25819966 0.25820563\n",
      " 0.15191745 0.25820563 0.25820314 0.25820563 0.25820563 0.25820336\n",
      " 0.25820563 0.2581988  0.25820336 0.25820051 0.25820392 0.2581988\n",
      " 0.25820336 0.09650013 0.25820544 0.25820336 0.25820478 0.25819966\n",
      " 0.25820222 0.25820051 0.25820051 0.25820392 0.25820563 0.15191745\n",
      " 0.25820563 0.15313514 0.25820563 0.25820563 0.05019216 0.25820563\n",
      " 0.25820563 0.25820563 0.25820545 0.15191738 0.25820563 0.15191736\n",
      " 0.25820563 0.08837167 0.04992997 0.2582054  0.25820563 0.04818492\n",
      " 0.084062   0.13875193 0.08406202 0.08407709 0.25820563 0.08410135\n",
      " 0.08406202 0.08413452]\n"
     ]
    }
   ],
   "source": [
    "print(data['volratt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr=np.column_stack((reg1.predict(X),reg2.predict(X),reg3.predict(X)))\n",
    "ytr.shape\n",
    "spio.savemat(lattice+'-tr-result',mdict={'coeffstr':data['ydata'],'coeffspred':ytr,'coord':data['coordt'],'mps':data['mps'],'volrat':data['volratt']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('reg1.p','rb') as f:\n",
    "    reg1=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('transformer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reg', BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'reg__alpha_1': [1e-06, 1e-05]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('reg3.p','rb') as f:\n",
    "    r3=pickle.load(f)\n",
    "r3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = spio.loadmat(lattice+'-nt-result')\n",
    "dd['coeffsnt']=dd['coeffsnt'].tolist()\n",
    "dd['coord']=dd['coord'].tolist()\n",
    "dd['volrat']=dd['volrat'].tolist()\n",
    "dd['mps']=dd['mps'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'bytes' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e0d5f4278c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlattice\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'-nt-result_noform.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[0;32m--> 180\u001b[0;31m                         o.__class__.__name__)\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type 'bytes' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(lattice+'-nt-result_noform.json','w') as f:\n",
    "    json.dump(dd,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('transformer', StandardScaler(copy=True, with_mean=True, with_std=True)), ('reg', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'reg__alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=linear_model.Lasso()\n",
    "params=models_and_parameters['lasso'][1]\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pipeline = Pipeline([('transformer', scaler), ('reg', model)])\n",
    "reg1lasso = GridSearchCV(estimator=pipeline, param_grid=params, cv=inner_cv,n_jobs=-1)\n",
    "reg1lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Folds: 3, mean r2: 0.616\n"
     ]
    }
   ],
   "source": [
    "reg1lasso.fit(X,y)\n",
    "reg1lasso.best_params_\n",
    "#scores=cross_val_score(reg2, X=X, y=y, scoring='neg_mean_squared_error',cv=outer_cv)\n",
    "r2scores=cross_val_score(reg1lasso, X=X, y=y, scoring='r2',cv=outer_cv)\n",
    "#rmse_scores = [np.sqrt(abs(s)) for s in scores]\n",
    "print('Cross-validation results:')\n",
    "#print('Folds: %i, mean RMSE: %.3f' % (len(scores), np.mean(np.abs(rmse_scores))))\n",
    "print('Folds: %i, mean r2: %.3f' % (len(r2scores), np.mean(r2scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reg1lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-73.99316211  46.3843869    4.75194328   3.0581043  -29.7807194\n",
      " -83.48320337  -2.59027984 -35.69553963   7.59154831 142.25994489\n",
      "  27.55151659 -15.72826648 -18.54535543  -5.91218868 -35.05286745\n",
      " 107.27319597  -6.11099286  50.10285911   0.        ]\n",
      "[-33.13148875  -5.31709399  -1.58192648  -0.96671281  -1.30384867\n",
      "   4.46508118  -1.00773901  -9.52158754   6.30148955  10.10122899\n",
      "  -3.9855769   -0.           0.25734102  10.1495421  -16.2522837\n",
      "  50.2334811    2.96694845   5.64221635   0.10404665]\n",
      "[-20.17605836   3.20680575  -1.27026152  -3.1777611   -7.89473839\n",
      "  -2.74887685   3.96638945 -16.79590484   4.25475666  23.67939975\n",
      "   7.57692893  -8.84518697   2.59918826   5.0206955  -13.94565021\n",
      "  11.83438023   3.21882829  10.74947255  11.82631575]\n"
     ]
    }
   ],
   "source": [
    "print(reg1lasso.best_estimator_.named_steps['reg'].coef_)\n",
    "print(reg2.best_estimator_.named_steps['reg'].coef_)\n",
    "print(reg3.best_estimator_.named_steps['reg'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('reg2_noform.p','rb') as f:\n",
    "    reg2=pickle.load(f)\n",
    "with open('reg3_noform.p','rb') as f:\n",
    "    reg3=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 16  6  1 18]\n",
      "[16  1 15 14 10]\n",
      "[10  1  8 15 16]\n"
     ]
    }
   ],
   "source": [
    "coef1=reg1lasso.best_estimator_.named_steps['reg'].coef_\n",
    "coef2=reg2.best_estimator_.named_steps['reg'].coef_\n",
    "coef3=reg3.best_estimator_.named_steps['reg'].coef_\n",
    "print(np.abs(coef1).argsort()[-5:][::-1]+1)\n",
    "print(np.abs(coef2).argsort()[-5:][::-1]+1)\n",
    "print(np.abs(coef3).argsort()[-5:][::-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
